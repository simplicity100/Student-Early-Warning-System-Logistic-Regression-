{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "277f815d-2919-41f5-97ee-1e1381ccb5a4",
   "metadata": {},
   "source": [
    "# Early Warning or Student Success Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af9ef50-3972-441a-b8e7-30a1de8d89d9",
   "metadata": {},
   "source": [
    "#### The factors required for Early Warning/Student Success Prediction are Academic: Prior GPA, Course Grades, Assignment/Quiz Scores, Attendance (%), LMS Activity (clicks/time), Study Hours; as well as Socioeconomic: Socioeconomic Score, Financial Aid Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd0ef57-1364-4cee-a771-2948f25738d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4783eedc-2d14-4481-a8ba-87b5ff31c5c1",
   "metadata": {},
   "source": [
    "#### Generate data for 2500 students based on the U.S. universities and colleges.\n",
    "\n",
    "##### Data Generation Logic\n",
    "For a full dataset of 2,500 students, the data would be generated using statistical methods to mimic real-world academic data:\n",
    "\n",
    "Continuous Factors (GPA, Grades, Study Hours, etc.): Values would be drawn from a Normal (Gaussian) distribution but bounded by the realistic minimum and maximum (e.g., 0 and 4.00 for GPA). The mean and standard deviation for each factor would be tuned to ensure the overall dataset is realistic (e.g., most students pass, but a significant tail shows risk).\n",
    "\n",
    "Categorical Factors (Financial Aid, Socioeconomic Score): Values would be drawn from a Multinomial or Bernoulli distribution. For instance, 'Financial Aid Status' (0/1) would be set to produce a desired ratio (e.g., 60% receive aid).\n",
    "\n",
    "Correlation Simulation: Crucially, for a predictive model, the factors should be correlated. For example:\n",
    "\n",
    "Higher Prior GPA tends to correlate with Higher Course Grade (%) and Higher Study Hours (hrs/wk).\n",
    "\n",
    "Lower Attendance (%) and Lower LMS Activity often correlate with Lower Course Grade (%) and a Financial Aid Status of 1 (due to external pressures)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4cc437-8723-4748-bc94-19dbb98a2275",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c255655-2826-411d-b099-786b4820e428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7c17ce8-dad0-4d61-ae1a-01348e736681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Synthetic Student Success Data (First 10 Rows) ---\n",
      "|   Student_ID |   Prior_GPA |   Course_Grade_Perc |   Assignment_Score_Perc |   Attendance_Perc |   LMS_Activity_Logins_Wk |   Study_Hours_Wk |   Financial_Aid_Status |   Socioeconomic_Score |   Outcome_At_Risk |\n",
      "|-------------:|------------:|--------------------:|------------------------:|------------------:|-------------------------:|-----------------:|-----------------------:|----------------------:|------------------:|\n",
      "|            1 |        3.61 |                  81 |                      97 |                88 |                       17 |             22.1 |                      0 |                     3 |                 0 |\n",
      "|            2 |        3.31 |                  74 |                      85 |                85 |                       14 |              6   |                      1 |                     3 |                 0 |\n",
      "|            3 |        3.52 |                  75 |                      94 |                90 |                       18 |             12.8 |                      0 |                     4 |                 0 |\n",
      "|            4 |        3.99 |                  94 |                      97 |               100 |                       27 |             16.3 |                      0 |                     5 |                 0 |\n",
      "|            5 |        2.84 |                  80 |                      80 |                92 |                       10 |             12.5 |                      0 |                     3 |                 0 |\n",
      "|            6 |        2.89 |                  68 |                      72 |                82 |                       10 |             23   |                      1 |                     3 |                 0 |\n",
      "|            7 |        4    |                 100 |                      98 |               100 |                       28 |             24.4 |                      0 |                     5 |                 0 |\n",
      "|            8 |        3.91 |                  90 |                      87 |                90 |                       16 |             16.1 |                      1 |                     4 |                 0 |\n",
      "|            9 |        2.65 |                  68 |                      77 |                80 |                        7 |             -0   |                      1 |                     3 |                 0 |\n",
      "|           10 |        3.26 |                  84 |                      87 |                96 |                       15 |             22.7 |                      0 |                     3 |                 0 |\n",
      "\n",
      "Successfully generated and saved 2500 student records to students_early_warning_2500.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- Configuration ---\n",
    "NUM_STUDENTS = 2500\n",
    "SEED = 42 # for reproducibility\n",
    "\n",
    "# Set seed for random number generation\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# --- 1. Generate Correlated Base Data ---\n",
    "# We'll generate a base \"latent success score\" (Z) and use it to drive all other variables.\n",
    "# This simulates the real-world correlation between factors.\n",
    "# A higher Z means a higher-performing student.\n",
    "Z = np.random.normal(loc=0, scale=1.5, size=NUM_STUDENTS)\n",
    "\n",
    "# --- 2. Generate Individual Factors based on Z ---\n",
    "\n",
    "# A. Prior GPA (Range: 0.00 - 4.00)\n",
    "# Use Z to pull the GPA up, then add some noise and clip.\n",
    "# Max GPA is 4.0, but we allow for high outliers (up to 4.2) before clipping to 4.0.\n",
    "gpa_base = 3.2 + (Z * 0.4) + np.random.normal(0, 0.2, NUM_STUDENTS)\n",
    "Prior_GPA = np.clip(gpa_base, 0.00, 4.00)\n",
    "\n",
    "# B. Course Grade (%) (Range: 0 - 100)\n",
    "# Strong relationship with Z (success score)\n",
    "grade_base = 78 + (Z * 8) + np.random.normal(0, 6, NUM_STUDENTS)\n",
    "Course_Grade_Perc = np.clip(np.round(grade_base), 0, 100).astype(int)\n",
    "\n",
    "# C. Assignment Score (%) (Range: 0 - 100)\n",
    "# Generally higher than final grade, but still correlated with Z\n",
    "assign_base = 85 + (Z * 5) + np.random.normal(0, 5, NUM_STUDENTS)\n",
    "Assignment_Score_Perc = np.clip(np.round(assign_base), 0, 100).astype(int)\n",
    "\n",
    "# D. Attendance (%) (Range: 0 - 100)\n",
    "# Skewed towards high attendance; inversely related to negative Z values\n",
    "attendance_base = 88 + (Z * 5) + np.random.normal(0, 5, NUM_STUDENTS)\n",
    "Attendance_Perc = np.clip(np.round(attendance_base), 50, 100).astype(int) # Min attendance 50%\n",
    "\n",
    "# E. Study Hours (hrs/wk) (Range: 0 - 60)\n",
    "# Correlated with Z, but with large variance (some smart/efficient students study less)\n",
    "study_base = 15 + (Z * 4) + np.random.normal(0, 8, NUM_STUDENTS)\n",
    "Study_Hours_Per_Week = np.clip(np.round(study_base, 1), 0, 60)\n",
    "\n",
    "# F. LMS Activity (logins/wk) (Range: 0 - 50)\n",
    "# Correlated with Z and Study Hours\n",
    "lms_base = 15 + (Z * 3) + np.random.normal(0, 5, NUM_STUDENTS)\n",
    "LMS_Activity_Logins = np.clip(np.round(lms_base), 0, 50).astype(int)\n",
    "\n",
    "# G. Financial Aid Status (1=Yes, 0=No)\n",
    "# Inversely related to success (Z); a higher financial aid rate for lower Z students\n",
    "# Overall ~60% receive aid\n",
    "Fin_Aid_Prob = 0.6 - (Z * 0.05) # Lower Z means higher probability of 1 (aid)\n",
    "Financial_Aid_Status = (np.random.rand(NUM_STUDENTS) < Fin_Aid_Prob).astype(int)\n",
    "\n",
    "# H. Socioeconomic Score (1=Low, 5=High)\n",
    "# Directly related to success (Z); using a categorical inverse transform\n",
    "# Map Z to 5 categories, with low Z mapping to 1 and high Z mapping to 5\n",
    "quantiles = pd.Series(Z).quantile([0.1, 0.3, 0.7, 0.9]).values\n",
    "Socioeconomic_Score = np.digitize(Z, quantiles) + 1\n",
    "Socioeconomic_Score = np.clip(Socioeconomic_Score, 1, 5) # Ensure scores are 1-5\n",
    "\n",
    "# --- 3. Create DataFrame ---\n",
    "data = pd.DataFrame({\n",
    "    'Student_ID': range(1, NUM_STUDENTS + 1),\n",
    "    'Prior_GPA': Prior_GPA.round(2),\n",
    "    'Course_Grade_Perc': Course_Grade_Perc,\n",
    "    'Assignment_Score_Perc': Assignment_Score_Perc,\n",
    "    'Attendance_Perc': Attendance_Perc,\n",
    "    'LMS_Activity_Logins_Wk': LMS_Activity_Logins,\n",
    "    'Study_Hours_Wk': Study_Hours_Per_Week,\n",
    "    'Financial_Aid_Status': Financial_Aid_Status,\n",
    "    'Socioeconomic_Score': Socioeconomic_Score\n",
    "})\n",
    "\n",
    "# --- 4. Add the Target Variable (Simulated Outcome) ---\n",
    "# Create a binary outcome (Success=1, At_Risk=0) based on multiple factors.\n",
    "# At-risk students are those with low Z, low grades, and high financial aid.\n",
    "is_at_risk = (\n",
    "    (data['Course_Grade_Perc'] < 70) & # Failed or near-failing grade\n",
    "    (data['Attendance_Perc'] < 80) &  # Poor attendance\n",
    "    (data['Prior_GPA'] < 2.5)         # Low prior performance\n",
    ") | (\n",
    "    (data['Course_Grade_Perc'] < 65) &\n",
    "    (data['Study_Hours_Wk'] < 5)\n",
    ") | (\n",
    "    (data['Financial_Aid_Status'] == 1) &\n",
    "    (data['Socioeconomic_Score'] < 3) &\n",
    "    (data['Course_Grade_Perc'] < 75)\n",
    ")\n",
    "\n",
    "data['Outcome_At_Risk'] = np.where(is_at_risk, 1, 0)\n",
    "\n",
    "# --- 5. Display and Save ---\n",
    "print(\"--- Synthetic Student Success Data (First 10 Rows) ---\")\n",
    "print(data.head(10).to_markdown(index=False))\n",
    "\n",
    "# Save the full dataset to a CSV file\n",
    "file_name = 'students_early_warning_2500.csv'\n",
    "data.to_csv(file_name, index=False)\n",
    "print(f\"\\nSuccessfully generated and saved {NUM_STUDENTS} student records to {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5119d2-24e1-42a3-a7ad-0fdc2299b5d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c98bcb77-986a-4cf9-90df-4e1904b391e2",
   "metadata": {},
   "source": [
    "#### The provided Python code generates a **synthetic dataset** of 2,500 student records for use in an **Early Warning System** (EWS) or **Student Success Prediction** model. The core principle of the code is to simulate **real-world correlations** between academic, socioeconomic, and behavioral factors by basing all variables on a single underlying \"latent success score.\"\n",
    "\n",
    "Here is a breakdown of the code's five main steps:\n",
    "\n",
    "## 1\\. Configuration and Latent Success Score\n",
    "\n",
    "The code starts by defining constants for the number of students (`NUM_STUDENTS = 2500`) and a random seed (`SEED = 42`) for reproducibility.\n",
    "\n",
    "The most critical part is the creation of the **Latent Success Score (`Z`)**:\n",
    "\n",
    "```python\n",
    "Z = np.random.normal(loc=0, scale=1.5, size=NUM_STUDENTS)\n",
    "```\n",
    "\n",
    "  * This score is a **single normally distributed random variable** (like an unseen talent or motivation level).\n",
    "  * A higher $Z$ value suggests a student is intrinsically more likely to succeed, while a lower $Z$ suggests a higher risk of academic failure.\n",
    "  * By making all other features mathematically dependent on $Z$, the code ensures that the generated variables are realistically correlated (e.g., high GPA is correlated with high study hours and high attendance).\n",
    "\n",
    "-----\n",
    "\n",
    "## 2\\. Generating Correlated Factors\n",
    "\n",
    "Each variable is generated by taking the base $Z$ score, applying a linear transformation (the `Z * factor` part), and adding some random noise to ensure realistic variability. Finally, the value is **clipped** to stay within the established realistic ranges for U.S. college data:\n",
    "\n",
    "  * **Academic Factors (GPA, Grades, Attendance, etc.):** The code adds $Z$ multiplied by a positive weight (e.g., `Z * 0.4` for GPA) to a mean baseline (e.g., `3.2` for GPA). This means students with a high $Z$ score are likely to have a high GPA, while students with a low $Z$ score will have a low GPA. The `np.clip` function forces all values to stay between the minimum (e.g., 0.00) and maximum (e.g., 4.00).\n",
    "  * **Socioeconomic Score (1 to 5):** This is created by dividing the $Z$ score distribution into five quantiles (or ranges). Students in the lowest $Z$ quantile are assigned a Socioeconomic Score of 1 (Low), and those in the highest quantile get a score of 5 (High), simulating the well-documented correlation between socioeconomic background and academic potential.\n",
    "  * **Financial Aid Status (0 or 1):** This factor is **inversely** related to $Z$. The probability of receiving financial aid (`Fin_Aid_Prob`) is set higher for students with a lower $Z$ score (`0.6 - (Z * 0.05)`). This simulates the reality that students from lower socioeconomic backgrounds (lower $Z$) are more likely to receive aid.\n",
    "\n",
    "-----\n",
    "\n",
    "## 3\\. Creating the DataFrame\n",
    "\n",
    "```python\n",
    "data = pd.DataFrame({\n",
    "    # ... all generated columns ...\n",
    "})\n",
    "```\n",
    "\n",
    "All the individual NumPy arrays are compiled into a single **Pandas DataFrame** for easy manipulation and storage, with `Student_ID` created as a simple counter.\n",
    "\n",
    "-----\n",
    "\n",
    "## 4\\. Creating the Target Variable (Outcome)\n",
    "\n",
    "The final step for the predictive model is creating the outcome, which is the variable the machine learning model will try to predict. Here, the target variable is **`Outcome_At_Risk` (1 for At-Risk, 0 for Success)**:\n",
    "\n",
    "```python\n",
    "is_at_risk = (\n",
    "    (data['Course_Grade_Perc'] < 70) & # Failed or near-failing grade\n",
    "    # ... combinations of low performance factors ...\n",
    ")\n",
    "data['Outcome_At_Risk'] = np.where(is_at_risk, 1, 0)\n",
    "```\n",
    "\n",
    "Instead of relying solely on the hidden $Z$ score, the code uses a **rule-based logic** to define risk, mimicking how an institution might manually flag a student:\n",
    "\n",
    "  * A student is flagged as **At-Risk (1)** if they meet specific combinations of poor performance, such as having a course grade below 70% AND poor attendance, OR if they are low-income (Aid=1, SES\\<3) AND have a course grade below 75%.\n",
    "  * This rule-based definition provides a clear, simulated target for the classification model to learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16a93f2-f151-46cf-b07b-0c30c77d560b",
   "metadata": {},
   "source": [
    "## Apply Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68aefb8a-dd0f-4320-86d3-5cac8737ed14",
   "metadata": {},
   "source": [
    "#### Applying Logistic Regression to the generated student data is the final, practical step to build your Early Warning System (EWS). Logistic Regression is ideal because your target outcome, Outcome_At_Risk, is binary (0 or 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef5531a-b81a-4bbe-8437-806ee2f7d9ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82bdd918-8560-4b3d-b859-940c55d0297e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student_ID</th>\n",
       "      <th>Prior_GPA</th>\n",
       "      <th>Course_Grade_Perc</th>\n",
       "      <th>Assignment_Score_Perc</th>\n",
       "      <th>Attendance_Perc</th>\n",
       "      <th>LMS_Activity_Logins_Wk</th>\n",
       "      <th>Study_Hours_Wk</th>\n",
       "      <th>Financial_Aid_Status</th>\n",
       "      <th>Socioeconomic_Score</th>\n",
       "      <th>Outcome_At_Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.61</td>\n",
       "      <td>81</td>\n",
       "      <td>97</td>\n",
       "      <td>88</td>\n",
       "      <td>17</td>\n",
       "      <td>22.1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.31</td>\n",
       "      <td>74</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>14</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3.52</td>\n",
       "      <td>75</td>\n",
       "      <td>94</td>\n",
       "      <td>90</td>\n",
       "      <td>18</td>\n",
       "      <td>12.8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3.99</td>\n",
       "      <td>94</td>\n",
       "      <td>97</td>\n",
       "      <td>100</td>\n",
       "      <td>27</td>\n",
       "      <td>16.3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.84</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>92</td>\n",
       "      <td>10</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Student_ID  Prior_GPA  Course_Grade_Perc  Assignment_Score_Perc  \\\n",
       "0           1       3.61                 81                     97   \n",
       "1           2       3.31                 74                     85   \n",
       "2           3       3.52                 75                     94   \n",
       "3           4       3.99                 94                     97   \n",
       "4           5       2.84                 80                     80   \n",
       "\n",
       "   Attendance_Perc  LMS_Activity_Logins_Wk  Study_Hours_Wk  \\\n",
       "0               88                      17            22.1   \n",
       "1               85                      14             6.0   \n",
       "2               90                      18            12.8   \n",
       "3              100                      27            16.3   \n",
       "4               92                      10            12.5   \n",
       "\n",
       "   Financial_Aid_Status  Socioeconomic_Score  Outcome_At_Risk  \n",
       "0                     0                    3                0  \n",
       "1                     1                    3                0  \n",
       "2                     0                    4                0  \n",
       "3                     0                    5                0  \n",
       "4                     0                    3                0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('students_early_warning_2500.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af265dee-c380-4c82-8a49-33249e9ea220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "\n",
    "\n",
    "# Define Features (X) and Target (y)\n",
    "# We drop the Student_ID as it's not predictive\n",
    "X = df.drop(['Student_ID', 'Outcome_At_Risk'], axis=1)\n",
    "y = df['Outcome_At_Risk']\n",
    "\n",
    "# Handle Categorical Data (Socioeconomic Score)\n",
    "# Since Socioeconomic_Score is ordinal (1-5), we can treat it as a numerical feature,\n",
    "# but for maximum model flexibility, we'll convert it to one-hot encoding (dummies).\n",
    "X = pd.get_dummies(X, columns=['Socioeconomic_Score'], drop_first=True) \n",
    "\n",
    "# Split data into training and testing sets\n",
    "# Use 80% for training the model and 20% for testing its performance on unseen data.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y) \n",
    "# stratify=y ensures the training and test sets have the same proportion of 'At-Risk' students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "227e004d-1aa1-454a-addc-f0a0493de2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression models converge faster and perform better when continuous features are scaled. \n",
    "# We use StandardScaler to standardize the features (mean=0, standard deviation=1).\n",
    "# Select the columns that are continuous and need scaling\n",
    "# (Exclude the Financial_Aid_Status and the new one-hot encoded SES columns)\n",
    "continuous_cols = ['Prior_GPA', 'Course_Grade_Perc', 'Assignment_Score_Perc', \n",
    "                   'Attendance_Perc', 'LMS_Activity_Logins_Wk', 'Study_Hours_Wk']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit scaler on the training data and transform both sets\n",
    "X_train[continuous_cols] = scaler.fit_transform(X_train[continuous_cols])\n",
    "X_test[continuous_cols] = scaler.transform(X_test[continuous_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea215e28-6e43-449a-9787-22adf33b377a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       395\n",
      "           1       0.90      0.97      0.94       105\n",
      "\n",
      "    accuracy                           0.97       500\n",
      "   macro avg       0.95      0.97      0.96       500\n",
      "weighted avg       0.97      0.97      0.97       500\n",
      "\n",
      "AUC-ROC Score: 0.9979\n",
      "\n",
      "--- Confusion Matrix (Actual vs. Predicted) ---\n",
      "[[384  11]\n",
      " [  3 102]]\n"
     ]
    }
   ],
   "source": [
    "# 1. Instantiate and train the Logistic Regression model\n",
    "log_reg_model = LogisticRegression(solver='liblinear', random_state=42)\n",
    "log_reg_model.fit(X_train, y_train)\n",
    "\n",
    "# 2. Make predictions on the test set\n",
    "# Predict the class (0 or 1)\n",
    "y_pred = log_reg_model.predict(X_test)\n",
    "\n",
    "# Predict the probability of being 'At-Risk' (1)\n",
    "y_proba = log_reg_model.predict_proba(X_test)[:, 1] \n",
    "\n",
    "# 3. Evaluate Model Performance\n",
    "\n",
    "# Classification Report (Precision, Recall, F1-Score)\n",
    "print(\"--- Classification Report ---\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# AUC-ROC Score (Overall discriminatory power)\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "print(f\"AUC-ROC Score: {auc:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\n--- Confusion Matrix (Actual vs. Predicted) ---\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f41ba03-110d-4fe4-9830-1336974cd0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Odds Ratios (Impact on being 'At-Risk') ---\n",
      "Financial_Aid_Status      55.965236\n",
      "LMS_Activity_Logins_Wk     1.044802\n",
      "Socioeconomic_Score_5      0.895983\n",
      "Attendance_Perc            0.812686\n",
      "Assignment_Score_Perc      0.800357\n",
      "Study_Hours_Wk             0.749711\n",
      "Socioeconomic_Score_2      0.670876\n",
      "Prior_GPA                  0.462064\n",
      "Socioeconomic_Score_4      0.179862\n",
      "Course_Grade_Perc          0.057199\n",
      "Socioeconomic_Score_3      0.008705\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Display coefficients as Odds Ratios\n",
    "feature_names = X_train.columns\n",
    "coefficients = log_reg_model.coef_[0]\n",
    "odds_ratios = pd.Series(np.exp(coefficients), index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "print(\"\\n--- Odds Ratios (Impact on being 'At-Risk') ---\")\n",
    "print(odds_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8198ba01-1578-4c3b-be65-10281db4e835",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391c6ad6-0c32-4591-b471-6f5ec0460e39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b310000-939c-4f9c-85e5-658aba64a27e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fabe766-66ac-4455-9654-ea8976db7441",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
